<?xml version="1.0" encoding="utf-8"?><!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xml:lang="no" lang="no" epub:prefix="nordic: http://www.mtm.se/epub/">
<head xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:dcterms="http://purl.org/dc/terms/">
    <meta charset="UTF-8" />
    <title>Metode og dataanalyse</title>
    <meta name="dc:identifier" content="501325" />
    <meta name="viewport" content="width=device-width" />
    <meta name="nordic:guidelines" content="2015-1" />
    <meta name="nordic:supplier" content="Planman" />
    <meta name="nordic:supplieddate" content="2011-10-04" />
    <meta name="nordic:signum" content="" />
    <meta content="Gripsrud, Geir" name="dc:creator" />
    <meta content="Olsson, Ulf Henning" name="dc:creator" />
    <meta content="Silkoset, Ragnhild" name="dc:creator" />
    <meta content="2011-10-04" name="dc:date" />
    <meta content="NLB" name="dc:publisher" />
    <meta content="no" name="dc:language" />
    <meta content="urn:isbn:978-82-7634-864-4-1" name="dc:source" />
    <style type="text/css" xml:space="preserve">
                .initialism{
                    -epub-speak-as:spell-out;
                }
                .list-style-type-none{
                    list-style-type:none;
                }
                table[class ^= "table-rules-"],
                table[class *= " table-rules-"]{
                    border-width:thin;
                    border-style:hidden;
                }
                table[class ^= "table-rules-"]:not(.table-rules-none),
                table[class *= " table-rules-"]:not(.table-rules-none){
                    border-collapse:collapse;
                }
                table[class ^= "table-rules-"] td,
                table[class *= " table-rules-"] td{
                    border-width:thin;
                    border-style:none;
                }
                table[class ^= "table-rules-"] th,
                table[class *= " table-rules-"] th{
                    border-width:thin;
                    border-style:none;
                }
                table.table-rules-none td,
                table.table-rules-none th{
                    border-width:thin;
                    border-style:hidden;
                }
                table.table-rules-all td,
                table.table-rules-all th{
                    border-width:thin;
                    border-style:solid;
                }
                table.table-rules-cols td,
                table.table-rules-cols th{
                    border-left-width:thin;
                    border-right-width:thin;
                    border-left-style:solid;
                    border-right-style:solid;
                }
                table.table-rules-rows tr{
                    border-top-width:thin;
                    border-bottom-width:thin;
                    border-top-style:solid;
                    border-bottom-style:solid;
                }
                table.table-rules-groups colgroup{
                    border-left-width:thin;
                    border-right-width:thin;
                    border-left-style:solid;
                    border-right-style:solid;
                }
                table.table-rules-groups tfoot,
                table.table-rules-groups thead,
                table.table-rules-groups tbody{
                    border-top-width:thin;
                    border-bottom-width:thin;
                    border-top-style:solid;
                    border-bottom-style:solid;
                }
                table[class ^= "table-frame-"],
                table[class *= " table-frame-"]{
                    border:thin hidden;
                }
                table.table-frame-void{
                    border-style:hidden;
                }
                table.table-frame-above{
                    border-style:outset hidden hidden hidden;
                }
                table.table-frame-below{
                    border-style:hidden hidden outset hidden;
                }
                table.table-frame-lhs{
                    border-style:hidden hidden hidden outset;
                }
                table.table-frame-rhs{
                    border-style:hidden outset hidden hidden;
                }
                table.table-frame-hsides{
                    border-style:outset hidden;
                }
                table.table-frame-vsides{
                    border-style:hidden outset;
                }
                table.table-frame-box{
                    border-style:outset;
                }
                table.table-frame-border{
                    border-style:outset;
                }</style>
    <link rel="stylesheet" type="text/css" href="css/accessibility.css" />
    <link rel="prev" href="501325-14-chapter.xhtml" />
    <link rel="next" href="501325-16-chapter.xhtml" />
</head>
<body id="level2_9" epub:type="bodymatter chapter">
<div id="page-189" class="page-normal" epub:type="pagebreak" title="189"></div><h1 id="h2_9">Kapittel 9 Hypotesetesting</h1><section id="level3_52"><h2 id="h3_52">9.1 Innledning</h2><p>Kapitlet om hypotesetesting er todelt. Vi skal f&#xf8;rst l&#xe6;re &#xe5; teste hypotesen om en stikkpr&#xf8;ve representerer populasjonen, deretter l&#xe6;re &#xe5; teste hypoteser om sammenhenger mellom utvalg og variabler (se figur 9.1).</p><p>For det f&#xf8;rste er det ofte slik at dataene vi har til variablene i et datasett, ikke er hentet fra hele populasjonen, men fra <em>stikkpr&#xf8;ver</em> fra populasjonen (se kapittel 6). I dette kapitlet skal vi l&#xe6;re en teknikk for &#xe5; teste om v&#xe5;re stikkpr&#xf8;ver faktisk representerer populasjonen eller ikke. Dette er t-testen for &#xe9;n stikkpr&#xf8;ve. Hvis for eksempel dataene v&#xe5;re skriver seg fra et representativt utvalg (stikkpr&#xf8;ve) fra en populasjon, vil det ofte v&#xe6;re av interesse &#xe5; unders&#xf8;ke om vi kan trekke slutninger fra det vi finner i utvalget til det som gjelder i populasjonen. Hvis vi finner at gjennomsnittlig kvadratmeterpris p&#xe5; boliger i byn&#xe6;re str&#xf8;k er klart h&#xf8;yere enn gjennomsnittlig kvadratmeterpris p&#xe5; boliger i landlige str&#xf8;k, &#xf8;nsker vi &#xe5; vite <em>hvor sikre</em> vi kan v&#xe6;re p&#xe5; at denne forskjellen eksisterer i hele landet (populasjonen) som helhet. Statistisk inferens handler nettopp om &#xe5; trekke konklusjoner om &#xe9;n eller flere egenskaper ved populasjonen p&#xe5; grunnlag av representative stikkpr&#xf8;ver fra &#xe9;n eller flere populasjoner (det er ofte hensiktsmessig &#xe5; betrakte populasjonen som uendelig stor).</p><figure id="imggroup_87" class="image"><img id="img_87" src="images/image087.jpg" alt="image" /><figcaption id="caption_85">Figur 9.1 Teknikker for hypotesetesting.</figcaption></figure><div id="page-190" class="page-normal" epub:type="pagebreak" title="190"></div><p>For det andre vil man i mange tilfeller teste om det er forskjell i egenskapene mellom to gjennomsnitt, eller teste korrelasjonen mellom to variabler. Egenskapene ved populasjonen kalles gjerne parametre, og vivil antaat hypotesetestingen inng&#xe5;r som en del av evalueringen av en teori. I denne sammenheng vil vi f&#xf8;lge det som er tradisjonen i samfunnsfag &#x2013; nemlig at det er den <em>alternative</em> hypotesen som representerer teorien.</p><p>To hypoteser formuleres: <em>H<sub>0</sub></em> nullhypotesen og <em>H<sub>1</sub></em> alternativ hypotese.</p><p>Nullhypotesen er typisk en hypotese som angir det omr&#xe5;det eller de verdiene parameteren kan forventes &#xe5; anta dersom teorien <em>ikke</em> skulle stemme &#x2013; at det <em>ingen</em> sammenheng er mellom variablene vi &#xf8;nsker &#xe5; teste. Den alternative hypotesen angir det omr&#xe5;det eller de verdiene som er forenlige med teorien &#x2013; at det er en forskjell eller sammenheng mellom variablene vi &#xf8;nsker &#xe5; teste. <em>Teorien er derved rasjonalet for hvorfor vi antar at det er noen sammenheng mellom variablene</em>.</p><p>Vi skal imidlertid starte dette kapitlet med en gjennomgang av hvilke feil man kan gj&#xf8;re n&#xe5;r man skal teste hypoteser, Type I-feil og Type II-feil, samt redegj&#xf8;re for skillet mellom teoretisk signifikans og statistisk signifikans.</p></section><section id="level3_53"><h2 id="h3_53">9.2 Feil ved hypotesetester</h2><p>Symboler og begreper som brukes i dette avsnittet, er som f&#xf8;lger:</p><table id="table_20"><tbody><tr><td rowspan="1" colspan="1">Corr (<em>X, Y</em>)</td><td rowspan="1" colspan="1">Korrelasjonen mellom <em>X</em> variabel og <em>Y</em> variabel</td></tr><tr><td rowspan="1" colspan="1"><em>H</em><sub>0</sub></td><td rowspan="1" colspan="1">Nullhypotesen</td></tr><tr><td rowspan="1" colspan="1"><em>H</em><sub>1</sub></td><td rowspan="1" colspan="1">Alternativhypotesen</td></tr><tr><td rowspan="1" colspan="1">|<em>t</em>|</td><td rowspan="1" colspan="1">testobservator for t-fordelingen</td></tr><tr><td rowspan="1" colspan="1"><em>t<sub>&#x3b1;</sub></em></td><td rowspan="1" colspan="1">kritisk verdi for t-fordelingen</td></tr><tr><td rowspan="1" colspan="1"><em>&#x3b1;</em></td><td rowspan="1" colspan="1">signifikansniv&#xe5;</td></tr><tr><td rowspan="1" colspan="1"><em>&#x3b2;</em></td><td rowspan="1" colspan="1">styrkesymbol, betaverdi</td></tr></tbody></table><section id="level4_63"><div id="page-191" class="page-normal" epub:type="pagebreak" title="191"></div><h3 id="h4_63">Type I- og Type II-feil</h3><p>Tenk deg at du sitter i juryen i en rettssak. Konsekvensen av juryens beslutning har fire muligheter. To av mulighetene er i tr&#xe5;d med virkeligheten: Man kan slippe en uskyldig person fri, eller man kan fengsle en skyldig person. Tenk deg imidlertid at bevisene i saken ikke er helt klare, det finnes kun indisier. Dersom du tolker bevisene for tungt, risikerer du &#xe5; d&#xf8;mme en uskyldig person til fengsel. Dersom du tolker bevisene til &#xe5; kun skyldes tilfeldigheter og ikke ha noen sammenheng med den tiltalte, risikerer du &#xe5; slippe en skyldig person fri! Dette illustrerer nettopp Type I-feil og Type II-feil. Type I-feil er den mest alvorlige feilen, og oppst&#xe5;r n&#xe5;r man forkaster en sann <em>H</em><sub>0</sub> (setter en uskyldig person i fengsel). Type II-feil oppst&#xe5;r n&#xe5;r man beholder en sann <em>H</em><sub>0</sub> (slipper fri en skyldig person). I avsnittet under skal vi forklare hva som menes med &#xe5; teste nullhypotesen, og vise det formelle hypoteseoppsettet som testes.</p><p>Dersom man studerer sammenhengen mellom stress p&#xe5; jobben (<em>S</em>) og underbemanning (<em>UB</em>), vil man v&#xe6;re tilb&#xf8;yelig til &#xe5; tro at det er en positiv sammenheng mellom de to variablene. En positiv sammenheng betyr at jo st&#xf8;rre underbemanningen er, jo mer stress er det p&#xe5; jobben. Dette kan man for eksempel <em>teste</em> ved &#xe5; m&#xe5;le korrelasjonen. Dersom det kan p&#xe5;vises at korrelasjonen er <em>statistisk signifikant</em> st&#xf8;rre enn null, har vi oppn&#xe5;dd st&#xf8;tte for p&#xe5;standen om at det er positiv sammenheng mellom stress og underbemanning.</p><p>Det formelle hypoteseoppsettet vil se slik ut:</p><p><em>H</em><sub>0</sub>: Corr (<em>S, UB</em>) = 0; <em>H</em><sub>1</sub>: Corr (<em>S, UB</em>) &gt; 0</p><p>Nullhypotesen <em>H</em><sub>0</sub> p&#xe5;st&#xe5;r at korrelasjonen mellom stress p&#xe5; jobben (<em>S</em>) og underbemanning (<em>UB</em>) er null, alts&#xe5; at det ikke er noen sammenheng. I den alternative hypotesen <em>H</em><sub>1</sub> p&#xe5;st&#xe5;s det at sammenhengen er positiv, alts&#xe5; at det er en positiv sammenheng mellom stress p&#xe5; jobben (<em>S</em>) og underbemanning (<em>UB</em>) (st&#xf8;rre enn 0). Kun &#xe9;n av hypotesene vil bli akseptert. Selve testen gjennomf&#xf8;res ved at man beregner en testobservator, |<em>t</em>|, ut fra stikkpr&#xf8;ven. Testobservatoren har en sannsynlighetsfordeling som er basert p&#xe5; at nullhypotesen er sann. <em>Merk at man antar at nullhypotesen er sann.</em></p><p>Om nullhypotesen skal forkastes eller gis st&#xf8;tte for som en mulighet, avhenger av st&#xf8;rrelsen p&#xe5; testobservatoren, dens sannsynlighetsfordeling og det valgte signifikansniv&#xe5;et (<em>&#x3b1;</em>-niv&#xe5;), mot kritisk verdi <em>t</em><sub>&#x3b1;</sub>. Dersom testobservatoren viser seg &#xe5; v&#xe6;re usannsynlig (usannsynlig stor) under <em>H</em><sub>0</sub>, vil nullhypotesen bli forkastet, og man vil p&#xe5;st&#xe5; at <em>H</em><sub>1</sub> er riktig: I v&#xe5;rt tilfelle p&#xe5;st&#xe5;r vi da at det er en positiv sammenheng mellom stress og underbemanning.</p><div id="page-192" class="page-normal" epub:type="pagebreak" title="192"></div><p>I praksis gj&#xf8;res dette som oftest ved at man sammenligner testobservatoren med en s&#xe5;kalt kritisk verdi for den gjeldende sannsynlighetsfordelingen. Denne kritiske verdien er &#xe5; finne i tabeller som er vedlagt i de fleste l&#xe6;reb&#xf8;ker i statistikk. Hvis testobservatoren |<em>t|</em> viser seg &#xe5; v&#xe6;re st&#xf8;rre enn den kritiske verdien, vil dette f&#xf8;re til at <em>H</em><sub>0</sub> forkastes. Det er imidlertid mulig at dette er feil, selv om t viser seg &#xe5; v&#xe6;re st&#xf8;rre enn den kritiske verdien. Den feilen vi beg&#xe5;r i en slik situasjon, kalles <em>Type I-feil</em>, men den er mer kjent under navnet &#xab;signifikansni-v&#xe5;et&#xbb;. Signifikansniv&#xe5;et angir alts&#xe5; sannsynligheten for &#xe5; forkaste en sann <em>H</em><sub>0</sub>. Dette betyr f&#xf8;lgende: <em>Vi p&#xe5;st&#xe5;r at det er en positiv sammenheng</em> mellom stress og underbemanning, selv om det i den virkelige verden <em>ikke er</em> en positiv sammenheng mellom stress og underbemanning.</p><section id="level5_22"><h4 id="h5_22">Type I-feil: Vi forkaster en sann H0</h4><p>Dersom vi i stedet feilaktig aksepterer <em>H</em><sub>0</sub> hvis alternativet <em>H</em><sub>1</sub> er riktig, beg&#xe5;r vi <em>Type II-feil</em>. En Type II-feil betyr med andre ord at vi aksepterer en nullhypotese som er usann. Sannsynligheten for &#xe5; avsl&#xf8;re en usann H<sub>0</sub> kalles testens styrke og symboliseres vanligvis med 1-<em>b</em>. Temaet for testens styrke ligger utenfor det som er intensjonen med denne boka, og vi vil derfor ikke g&#xe5; n&#xe6;rmere inn p&#xe5; det her, men bare nevne at testens styrke vil &#xf8;ke n&#xe5;r utvalgsst&#xf8;rrelsen &#xf8;ker. Det er med andre ord lettere &#xe5; avsl&#xf8;re en usann nullhypotese n&#xe5;r utvalget (stikkpr&#xf8;ven) er stort, enn n&#xe5;r det er lite. En Type II-feil er &#xe5; <em>p&#xe5;st&#xe5; at det ikke er en positiv sammenheng</em> mellom stress og underbemanning, selv om det i den virkelige verden <em>er</em> en positiv sammenheng mellom stress og underbemanning. Type II-feil kommer av at testen har for lav styrke, <em>b</em>.</p></section><section id="level5_23"><h4 id="h5_23">Type II-feil: Vi beholder en usann H0</h4><p>Tabell 9.1 viser at det er fire mulige situasjoner som avgj&#xf8;r om vi tar riktige beslutninger n&#xe5;r vi tester en hypotese. Type I-feil og Type II-feil er nevnt. Dersom <em>H</em><sub>0</sub> er sann, og testen ogs&#xe5; indikerer at <em>H</em><sub>0</sub> skal gis st&#xf8;tte, tar man en riktig beslutning. En riktig beslutning tar man ogs&#xe5; dersom <em>H</em><sub>0</sub> er feilaktig eller usann, og testen identifiserer dette.</p><table id="table_21"><tbody><tr><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><em>H</em><sub>0</sub> er sann</td><td rowspan="1" colspan="1"><em>H</em><sub>0</sub> er usann</td></tr><tr><td rowspan="1" colspan="1"><em>H</em><sub>0</sub> beholdes</td><td rowspan="1" colspan="1">Riktig beslutning</td><td rowspan="1" colspan="1">Type II-feil (<em>&#x3b2;</em>)</td></tr><tr><td rowspan="1" colspan="1"><em>H</em><sub>0</sub> forkastes</td><td rowspan="1" colspan="1">Type I-feil (<em>&#x3b1;</em>)</td><td rowspan="1" colspan="1">Riktig beslutning</td></tr></tbody></table><p>Tabell 9.1 Type I-feil og Type II-feil.</p></section></section><section id="level4_64"><div id="page-193" class="page-normal" epub:type="pagebreak" title="193"></div><h3 id="h4_64">Teoretisk signifikans og statistisk signifikans</h3><p>I en artikkel i <em>The Economist</em> (2004) p&#xe5;peker man det viktige skillet mellom teoretisk signifikans og statistisk signifikans (se figur 9.2). Selv om det i denne boka fokuseres p&#xe5; hvordan man kan gjennomf&#xf8;re unders&#xf8;kelser p&#xe5; en metodisk riktig m&#xe5;te, slik at man minimerer Type I-feil og Type II-feil, betyr ikke dette at de p&#xe5;st&#xe5;tte sammenhengene automatisk er teoretisk interessante.</p><figure id="imggroup_88" class="image"><img id="img_88" src="images/image088.jpg" alt="image" /><figcaption id="caption_86">Figur 9.2 Signifying nothing (The Economist 2004).</figcaption></figure><p>I unders&#xf8;kelser som har til hensikt &#xe5; generere ny teoretisk kunnskap, er det s&#xe6;rdeles viktig &#xe5; v&#xe6;re oppmerksom p&#xe5; forskjellen mellom disse to typene signifikans. Med dette menes at en studie kan p&#xe5;vise at hypotesene er signifikante statistisk, men det beh&#xf8;ver ikke &#xe5; inneb&#xe6;re at det er noe teoretisk belegg for &#xe5; p&#xe5;st&#xe5; relasjonen. Faktisk vil man, ved &#xe5; ha et veldig stort utvalg, nesten alltid f&#xe5; statistisk signifikante sammenhenger, selv for sammenhenger som er meningsl&#xf8;se. Dette krever at den som foretar unders&#xf8;kelsen, alltid er kritisk til de funn man oppn&#xe5;r og sp&#xf8;r om i hvilken grad funnene virkelig har <em>betydning</em>. Grunnen er at man p&#xe5; et senere tidspunkt alltid skal kunne stole p&#xe5; at de teorier man st&#xf8;tter seg til, er gyldige. En vanlig feil som gj&#xf8;res, er &#xe5; ikke teste for spuri&#xf8;se effekter &#x2013; at sammenhengene vi f&#xe5;r belegg for statistisk, faktisk ikke eksisterer dersom vi kontrollerer for andre forklaringsmekanismer. Vi kommer mer tilbake til disse problemene i kapitlet om regresjonsanalyse.</p></section><section id="level4_65"><h3 id="h4_65">Forst&#xe5; signifikansniv&#xe5;</h3><p>I en signifikanstest tester vi om vi kan forkaste <em>nullhypotesen</em> (falsifisering). Dersom det er 100 % sikkerhet for at nullhypotesen er sann, vil den rapporterte signifikansverdien v&#xe6;re 1,00. Dersom det er 0 % sikkerhet for at nullhypotesen er sann, vil den rapporterte signifikansverdien v&#xe6;re 0,00. Vi opererer imidlertid aldri med slike verdier i v&#xe5;r type studier. Ved &#xe5; ta 1 &#x2013; rapportert signifikansverdi (f.eks. 1 &#x2013; 0,05 = 0,95 dvs. 95 %) f&#xe5;r vi st&#xf8;rrelsen p&#xe5; hvor sikre vi er p&#xe5; at <em>alternativhypotesen</em> gis st&#xf8;tte. Det er akseptert i v&#xe5;r type analyse at et signifikansniv&#xe5; <span id="page-194" class="page-normal" epub:type="pagebreak" title="194"></span>p&#xe5; 5 % (vi er 95 % sikre p&#xe5; at sammenhengen vi p&#xe5;st&#xe5;r i alternativhypotesen ikke kun skyldes tilfeldigheter) er tilstrekkelig.</p></section></section><section id="level3_54"><h2 id="h3_54">9.3 Student t-test</h2><section id="level4_66"><h3 id="h4_66">t-test for &#xe9;n stikkpr&#xf8;ve</h3><p>Den f&#xf8;rste testen vi skal g&#xe5; igjennom, er <em>t-testen</em> for en stikkpr&#xf8;ve. I v&#xe5;re statistiske beregninger antar vi at populasjonen er normalfordelt og bruker f&#xf8;lgende symboler:</p><table id="table_22"><tbody><tr><td rowspan="1" colspan="1"><em>&#x3bc;</em></td><td rowspan="1" colspan="1">gjennomsnitt for populasjonen</td></tr><tr><td rowspan="1" colspan="1"><em>&#x3bc;</em><sub>0</sub></td><td rowspan="1" colspan="1">hypotetisk gjennomsnitt</td></tr><tr><td rowspan="1" colspan="1"><span class="asciimath">`barX`</span></td><td rowspan="1" colspan="1">gjennomsnitt for utvalget</td></tr><tr><td rowspan="1" colspan="1">&#x3bc;<sup>2</sup></td><td rowspan="1" colspan="1">varians for populasjonen</td></tr><tr><td rowspan="1" colspan="1"><em>s</em><sup>2</sup></td><td rowspan="1" colspan="1">varians for utvalget</td></tr><tr><td rowspan="1" colspan="1"><span class="asciimath">`s_barX^2`</span></td><td rowspan="1" colspan="1">varians for utvalgets gjennomsnitt</td></tr><tr><td rowspan="1" colspan="1"><span class="asciimath">`sbarx`</span></td><td rowspan="1" colspan="1">standardavvik for utvalgets gjennomsnitt</td></tr><tr><td rowspan="1" colspan="1"><em>t<sub>&#x3b1;</sub></em></td><td rowspan="1" colspan="1">kritisk verdi for t-fordelingen</td></tr><tr><td rowspan="1" colspan="1">|<em>t|</em></td><td rowspan="1" colspan="1">testobservator for t-fordelingen</td></tr></tbody></table><p>Vi setter opp hypotesen om at populasjonens gjennomsnitt er lik det hypotetiske (konstruerte) gjennomsnittet <em>&#x3bc;</em><sub>0</sub>:</p><p><span class="asciimath">`H_0:mu_0 = mu_0`</span></p><p><span class="asciimath">`H_1:mu_0 != mu_0`</span></p><p>Testobservatoren <span class="asciimath">`t = (barX - mu_0)/(S_barx)`</span></p><p><em>Testobservatoren</em> er med andre ord utvalgets faktiske gjennomsnitt minus hypotetisk gjennomsnitt, delt p&#xe5; standardavviket til utvalgets gjennomsnitt (se kapittel 8 for formelen for standardavvik). Kritisk verdi <em>t<sub>&#x3b1;</sub></em> finner vi i tabellen for <em>t-fo</em>rdelingen (Vedlegg 3B), med <span class="asciimath">`h_delta-delta1`</span> frihetsgrader. Dersom <span class="asciimath">`|t| &gt; t_alpha`</span> vil vi forkaste <em>H</em><sub>0</sub> og p&#xe5;st&#xe5; at den alternative hypotesen er riktig. Logikken i <em>t-testen</em> er &#xe5; teste i hvor stor grad stikkpr&#xf8;vens gjennomsnittsverdi avviker fra den hypotetiske verdien <em>relativt</em> til variabiliteten eller usikkerheten i estimatet <span class="asciimath">`s_barx`</span>.</p><div id="page-195" class="page-normal" epub:type="pagebreak" title="195"></div><p>EKSEMPEL 9.1</p><p>La oss analysere dataene for caset Cure. Datasettet finnes bak i boka og p&#xe5; bokas hjemmeside. La oss anta at helseforetak i Norge i gjennomsnitt har 40 % gjennomtrekk av ansatte. Vi antar at helseforetaket Cure i gjennomsnitt for 2010 hadde <em>under</em> 40 % som &#xf8;nsket &#xe5; slutte (ensidig test). Nullhypotesen og alternativet (ensidig) kan vi stille opp p&#xe5; f&#xf8;lgende m&#xe5;te:</p><p><span class="asciimath">`H_0:mu_0 = 40%`</span></p><p><span class="asciimath">`H_0:mu_0  &lt;  40%`</span></p><p>Vi beregner testobservatoren i JMP (figur 9.3) p&#xe5; f&#xf8;lgende m&#xe5;te:</p><p><em>Analyze</em> &gt; <em>Distribution</em> &gt; <em>Y, Columns</em></p><figure id="imggroup_89" class="image"><img id="img_89" src="images/image089.jpg" alt="image" /><figcaption id="caption_87">Figur 9.3 Dialogboks for frekvens i JMP.</figcaption></figure><p>For &#xe5; teste 40 %-verdien gj&#xf8;r man f&#xf8;lgende:</p><p><em>R&#xf8;d trekant</em> &gt; <em>Test Mean</em></p><p>Man legger s&#xe5; inn &#xf8;nsket verdi. I v&#xe5;rt tilfelle 40, se Figur 9.4.</p><figure id="imggroup_90" class="image"><img id="img_90" src="images/image090.jpg" alt="image" /><figcaption id="caption_88">Figur 9.4 Test av gjennomsnittsverdi i JMP.</figcaption></figure><div id="page-196" class="page-normal" epub:type="pagebreak" title="196"></div><p>For det f&#xf8;rste viser utskriften at helseforetaket Cure i gjennomsnitt har 46,28 % gjennomtrekk av ansatte. Gjennomsnittet til stikkpr&#xf8;ven er 6,28 % st&#xf8;rre enn populasjonens 40 %. Frihetsgradene beregnes ved &#xe5; taantall observasjoner minus en, noe som gir oss <span class="asciimath">`(n - 1) = (25 - 1) = 24`</span> frihetsgrader. Testobservatoren er p&#xe5; 1,07. Fordi vi gjennomf&#xf8;rer testen p&#xe5; 5 %-niv&#xe5;et (ensidig test), velger vi &#xe5; ikke forkaste nullhypotesen, fordi testobservatoren p&#xe5; t = 1,07  &lt;  kritisk verdi p&#xe5; 1,711. Kritisk verdi finner vi i tabell for t-fordeling i vedlegg 3B under 24 frihetsgrader. Det er imidlertid ikke n&#xf8;dvendig &#xe5; sl&#xe5; opp i tabellen, ettersom JMP rapporterer signifikansniv&#xe5;et direkte 1&#x2013;0,853, det vil si 14,7 %.</p><p>Oppsummert finner vi at de faktiske forholdene er at populasjonens gjennomsnitt er mindre enn Cures gjennomsnitt, <em>&#x3bc;</em> &gt; <em>&#x3bc;</em><sub>0</sub>, det vil si 40  &lt;  46,28 og nullhypotesen kan derfor ikke forkastes. <em>Konklusjonen</em> er at gjennomsnittlig gjennomtrekk av ansatte i Cure faktisk ser ut til &#xe5; v&#xe6;re st&#xf8;rre enn for resten av populasjonen.</p><figure id="imggroup_91" class="image"><img id="img_91" src="images/image091.jpg" alt="image" /><figcaption id="caption_89">Tabell 9.2 Utskrift fra test av gjennomsnittsverdi i JMP.</figcaption></figure></section><section id="level4_67"><div id="page-197" class="page-normal" epub:type="pagebreak" title="197"></div><h3 id="h4_67">t-test for to stikkpr&#xf8;ver</h3><p>Hittil har vi g&#xe5;tt igjennom t-testen for &#xe9;n stikkpr&#xf8;ve. Vi skan n&#xe5; g&#xe5; igjennom to andre t-tester, dette er blant annet t-test av to <em>uavhengige</em> stikkpr&#xf8;ver (Independent samples t-test) og t-test av to <em>avhengige</em> stikkpr&#xf8;ver (Paired samples t-test). Vi kan forklare skillet mellom t-test av uavhengig og avhengig stikkpr&#xf8;ve p&#xe5; denne m&#xe5;ten: En t-test av uavhengig stikkpr&#xf8;ve vil for eksempel teste om det er noe skille p&#xe5; kj&#xf8;nn og sykefrav&#xe6;r i en bedrift. En t-test av avhengige stikkpr&#xf8;ver vil teste om det er forskjell p&#xe5; sykefrav&#xe6;ret fra &#xe5;r 2009 til &#xe5;r 2010. Vi skal f&#xf8;rst gjennomg&#xe5; t-testen av to avhengige stikkpr&#xf8;ver.</p><section id="level5_24"><h4 id="h5_24">a) t-testen av to avhengige stikkpr&#xf8;ver</h4><p>t-testen av to avhengige stikkpr&#xf8;ver bruker vi for eksempel n&#xe5;r vi skal teste to populasjoner mot hverandre, for &#xe5; se om det er noen forskjell mellom dem. La oss tenke oss at vi vil teste om l&#xf8;nnskostnadene for en bedrift var lik for september 2009 <em>&#x3bc;</em>1 mot september 2010 <em>&#x3bc;</em><sub>2</sub>. Igjen skriver vi opp hypotesene:</p><p><span class="asciimath">`H_0: mu_1 = mu_2`</span></p><p><span class="asciimath">`H_1: mu_1 != mu_2`</span></p><p>Vi ser for det f&#xf8;rste at dette er en tosidig test (vi har ikke spesifisert om <em>&#x3bc;</em><sub>1</sub> mot for <em>&#x3bc;</em><sub>2</sub> er st&#xf8;rre eller mindre, bare ulik). Hypotesen viser at vi antar at det <em>er</em> en faktisk forskjell mellom l&#xf8;nnskostnadene for september 2009 mot september 2010<em>. &#x3bc;</em><sub>1</sub> og <em>&#x3bc;</em><sub>2</sub> er gjennomsnittsverdiene for de to uavhengige populasjonene. B&#xe5;de populasjonsgjennomsnittene <em>&#x3bc;</em><sub>1</sub> og <em>&#x3bc;</em><sub>1</sub> og de to variansene <span class="asciimath">`sigma_1^2`</span> og <span class="asciimath">`sigma_2^2`</span> antas &#xe5; v&#xe6;re ukjente st&#xf8;rrelser. Fordi vi ikke kjenner populasjonsverdien, bruker vi verdiene fra stikkpr&#xf8;ven. Dette er gjennomsnittet til utvalget <span class="asciimath">`barX`</span> og variansen til utvalget. Igjen testes <em>H</em><sub>0</sub> ved hjelp av testobservatoren (Pooled: vi antar lik varians) som vi n&#xe5; finner i f&#xf8;lgende ligning for tosidig test:</p><p>Testobservatoren <span class="asciimath">`t = (barX_1 - barX_2)/(S(barX_1 - barX_2))`</span></p><p>Antall frihetsgrader, <em>v</em>, finner vi ved &#xe5; ta utvalgsst&#xf8;rrelsen <em>n,</em> minus 1 (<em>n</em> - 1) for hver av stikkpr&#xf8;vene, <span class="asciimath">`(n_1 - 1) + (n_2 - 1)`</span>. Variansestimatet er gitt ved:</p><p><span class="asciimath">`S_((barx_1 - barx_2))^2 = (sum_i(x_(1i) - barx_1)^2 + sum_i(x_(2i) - barx_2)^2)/((n_1 - 1) + (n_2 - 1))[1/n_1 + 1/n_2]`</span></p><div id="page-198" class="page-normal" epub:type="pagebreak" title="198"></div><figure id="imggroup_92" class="image"><img id="img_92" src="images/image092.jpg" alt="image" /><figcaption id="caption_90">Figur 9.5 Dialogboks for t-test av to avhengige stikkpr&#xf8;ver i JMP.</figcaption></figure><p>EKSEMPEL 9.2</p><p>La oss teste om l&#xf8;nnskostnadene fra september 2009 er forskjellig fra l&#xf8;nnskostnadene i september 2010. I JMP gj&#xf8;r vi det p&#xe5; f&#xf8;lgende m&#xe5;te (se figur 9.5):</p><p><em>Analyze</em> &gt; <em>Matched Pairs</em> &gt; <em>Y, Paired Response</em></p><p>Fra utskriftene ser vi at i september 2009 hadde bedriften gjennomsnittlige l&#xf8;nnskostnader p&#xe5; 26 840 kroner, mens for september 2010 var l&#xf8;nnskostnadene i gjennomsnitt p&#xe5; 27 901 kroner. Forskjellen i gjennomsnitt var p&#xe5; 1061 kroner. <em>Sp&#xf8;rsm&#xe5;let er imidlertid om denne forskjellen er stor nok til at den ikke bare skyldes tilfeldigheter.</em> For dette trenger vi &#xe5; se p&#xe5; testobservatoren og kritisk verdi.</p><figure id="imggroup_93" class="image"><img id="img_93" src="images/image093.jpg" alt="image" /><figcaption id="caption_91">Tabell 9.3 t-test av to avhengige stikkpr&#xf8;ver i JMP.</figcaption></figure><div id="page-199" class="page-normal" epub:type="pagebreak" title="199"></div><p>Testobservatoren i v&#xe5;r analyse er p&#xe5; 0,92. Fordi vi behandler testobservatoren med absoluttegnene |t|, har det ikke noe &#xe5; bety om t-verdien er positiv + eller negativ &#x2013;. Frihetsgradene for v&#xe5;r analyse er 9, og ved &#xe5; sl&#xe5; opp i t-fordelingen i vedlegg 3B ser vi at kritisk verdi (<em>t<sub>&#x3b1;</sub></em><sub>/2</sub>) for 2,5 % (tosidig)<a id="noteref_1" class="noteref" epub:type="noteref" href="501325-32-footnotes.xhtml#fn_9_1">1</a> er p&#xe5; 2,26 (9 frihetsgrader). Testobservatoren er alts&#xe5; lavere enn kritisk verdi, og forskjellen er derfor <em>ikke statistisk signifikant</em>. Fra utskriften ser vi at dette stemmer, signifi-kanssannsynligheten er p&#xe5; 1&#x2013;0,379, det vil si 62 %.</p><p>Derfor <em>konkluderer</em> vi med at det <em>ikke</em> er noen signifikant forskjell i l&#xf8;nnskostnadene mellom september 2009 og september 2010. Husk at ikke-signifkante funn ogs&#xe5; kan v&#xe6;re verdifull informasjon.</p></section><section id="level5_25"><h4 id="h5_25">a) t-testen for to uavhengige stikkpr&#xf8;ver</h4><figure id="imggroup_94" class="image"><img id="img_94" src="images/image094.jpg" alt="image" /><figcaption id="caption_92">Figur 9.6 Dialogboks for t-test av uavhengige stikkpr&#xf8;ver.</figcaption></figure><p>La oss tenke oss at vi &#xf8;nsker &#xe5; teste om l&#xf8;nnskostnadene for et IT-selskaps avdeling i Oslo er forskjellige fra selskapets avdeling i Troms&#xf8;. Det er snakk om et lite selskap med seks ansatte i Oslo og fire ansatte i Troms&#xf8;.</p><p>F&#xf8;rst skriver vi opp hypotesene:</p><p><span class="asciimath">`H_0: mu_1 = mu_2`</span></p><p><span class="asciimath">`H_1: mu_1 != mu_2`</span></p><p><em>&#x3bc;</em><sub>1</sub> er gjennomsnittlige l&#xf8;nnskostnader i Oslo, mens <em>&#x3bc;</em><sub>2</sub> er gjennomsnittlige l&#xf8;nnskostnader i Troms&#xf8;. Vi p&#xe5;st&#xe5;r at l&#xf8;nnskostnadene p&#xe5; de to stedene var forskjellige i september 2010 (tosidig test). La oss enkelt teste dette ved hjelp av JMP <em>Analyze</em> &gt; <em>Fit Y by X</em></p><div id="page-200" class="page-normal" epub:type="pagebreak" title="200"></div><p>I utskriften velger vi flere analyser. Vi &#xf8;nsker &#xe5; ha med beskrivende statistikk og t-test. Dette gj&#xf8;r vi p&#xe5; f&#xf8;lgende m&#xe5;te:</p><p><em>R&#xf8;d trekant</em> &gt; <em>Means and St. Dev</em></p><p><em>R&#xf8;d trekant</em> &gt; <em>Compare Means</em> &gt; <em>Each Pairs, Students t.</em></p><p>Utskriften ser n&#xe5; ut som f&#xf8;lger:</p><figure id="imggroup_95" class="image"><img id="img_95" src="images/image095.jpg" alt="image" /><figcaption id="caption_93">Tabell 9.4 Utskrift fra t-test av uavhengige stikkpr&#xf8;ver.</figcaption></figure><p>I utskriften ser vi for det f&#xf8;rste at de seks ansatte i Oslo-avdelingen i gjennomsnitt har 34 251 kroner i m&#xe5;nedsl&#xf8;nn, mens de fire ansatte i Troms&#xf8; har 18 375 kroner i gjennomsnittlig m&#xe5;nedsl&#xf8;nn. Dette gir en forskjell p&#xe5; 15 876 kroner. Sp&#xf8;rsm&#xe5;let er s&#xe5; om denne forskjellen er stor nok til at vi kan stole p&#xe5; den, eller om den kun skyldes tilfeldigheter.</p><div id="page-201" class="page-normal" epub:type="pagebreak" title="201"></div><p>I resultatet fra t-testen underst ser vi at testobservatoren (<em>t</em>-verdien) er p&#xe5; -2,38 (fortegnet p&#xe5; <em>t-</em>verdien har ingen betydning n&#xe5;r vi har en tosidig test, se forklaring i kapittel 10). Vi ser at signifikansniv&#xe5;et er p&#xe5; 0,043, det vil si p-verdi  &lt;  0,05, og forskjellen i gjennomsnittene mellom de to avdelingene kan ikke skyldes tilfeldighet. Vi kan ogs&#xe5; teste dette ved &#xe5; sjekke testobservatoren opp mot kritisk t som vi finner i vedlegg 3B. Kritisk t under 8 frihetsgrader og signifi-kansniv&#xe5; p&#xe5; 5 % er 2,30 (husk at vi deler signifikansniv&#xe5;et p&#xe5; 2 n&#xe5;r vi analyserer tosidige tester). Fordi <span class="asciimath">`|t| &gt; t_(alpha//2)`</span>, det vil si |2,38| &gt; 2,30, kan vi forkaste nullhypotesen.</p><p>JMP har innebygd mulighet for &#xe5; se dette visuelt ved &#xe5; klikke p&#xe5; den ene sirkelen i &#xf8;verste graf. De som blir markert, er de som er signifikant like hverandre. I v&#xe5;rt eksempel ser vi at kun Oslo blir markert n&#xe5;r vi klikker p&#xe5; den sirkelen. Dermed ser vi hvilke grupper som er signifikant forskjellig fra hverandre.</p><p>Grafisk kan vi framstille denne forskjellen p&#xe5; f&#xf8;lgende m&#xe5;te (se figur 9.7):</p><figure id="imggroup_96" class="image"><img id="img_96" src="images/image096.jpg" alt="image" /><figcaption id="caption_94">Figur 9.7 Grafisk illustrasjon av forskjell i gjennomsnitt.</figcaption></figure><p><em>Konklusjonen</em> er dermed at det er en gjennomsnittlig forskjell i l&#xf8;nnskostnadene mellom Oslo- og Troms&#xf8;-avdelingene for september 2010.</p></section></section></section><section id="level3_55"><h2 id="h3_55">9.4 Variansanalyse</h2><p>Nye symboler og begreper for variansanalyse:</p><table id="table_23"><tbody><tr><td rowspan="1" colspan="1"><em>TSS</em></td><td rowspan="1" colspan="1">total variabilitet</td></tr><tr><td rowspan="1" colspan="1"><em>SSIG</em></td><td rowspan="1" colspan="1">summen av variabilitet innenfor gruppene</td></tr><tr><td rowspan="1" colspan="1"><em>MSSIG</em></td><td rowspan="1" colspan="1">gjennomsnittlig variabilitet innenfor gruppene</td></tr><tr><td rowspan="1" colspan="1"><span id="page-202" class="page-normal" epub:type="pagebreak" title="202"></span><em>SSMG</em></td><td rowspan="1" colspan="1">summen av variabilitet mellom gruppene</td></tr><tr><td rowspan="1" colspan="1"><em>MSSMG</em></td><td rowspan="1" colspan="1">gjennomsnittlig variabilitet mellom gruppene</td></tr><tr><td rowspan="1" colspan="1"><em>&#xb5;</em><sub>1</sub>,<em>&#xb5;</em><sub>2</sub></td><td rowspan="1" colspan="1">populasjon 1 og populasjon 2</td></tr><tr><td rowspan="1" colspan="1"><em>X<sub>ij</sub></em></td><td rowspan="1" colspan="1">observasjon nr. <em>j</em> fra populasjon nr. <em>i</em></td></tr><tr><td rowspan="1" colspan="1"><em><span class="asciimath">`F_alpha`</span></em></td><td rowspan="1" colspan="1">testobservatoren for F-fordelingen</td></tr><tr><td rowspan="1" colspan="1"><em>F<sub>a</sub></em></td><td rowspan="1" colspan="1">kritisk verdi for F-fordelingen</td></tr><tr><td rowspan="1" colspan="1"><em>k</em></td><td rowspan="1" colspan="1">antall grupper</td></tr></tbody></table><p>Variansanalyse f&#xf8;lger samme logikk som t-test for to uavhengige stikkpr&#xf8;ver, bortsett fra at vi n&#xe5; har tre eller flere stikkpr&#xf8;ver. La oss tenke oss at de ansatte p&#xe5; IT-bedriften har tre l&#xf8;nnskompensasjonssystemer &#xe5; velge mellom &#x2013; fastl&#xf8;nn, fastl&#xf8;nn og provisjon, samt kun provisjonsbasert l&#xf8;nn. Dersom vi &#xf8;nsker &#xe5; teste om forskjellen i l&#xf8;nnskostnadene mellom disse tre typene av l&#xf8;nnskompensasjoner er statistisk signifikant forskjellig fra hverandre, m&#xe5; vi benytte F-fordelingen. Dette er fordi t-testene har den begrensning at de kun kan behandle opp til to grupper. N&#xe5;r det er tre grupper eller flere, benytter vi derfor variansanalyse, ANOVA. Variansanalyse kan benyttes for &#xe5; teste om gjennomsnittsverdier fra flere populasjoner er statistisk signifikant forskjellige. N&#xe5;r vi har f&#xe5;tt stadfestet det, kan vi bruke t-test til &#xe5; sammenligne parvise grupper. Variansanalyse er basert p&#xe5; sammenligning av to variansestimater: test innenfor gruppene (hvor stor variasjon det er i l&#xf8;nnen til de som for eksempel har fastl&#xf8;nn) og test mellom gruppene (hvor stor variasjon det er mellom de tre gruppene av l&#xf8;nnskompensasjoner).</p><p>Dersom datamaterialet er delt inn i grupper hvor hver gruppe er &#xe5; betrakte som tilfeldig stikkpr&#xf8;ve fra hver sin populasjon, beregnes det ene estimatet ut fra forskjeller i verdiene (scorene) innenfor hver gruppe. Det andre estimatet beregnes ut fra forskjeller i gjennomsnittsverdier p&#xe5; tvers av gruppene. Dette estimatet antas &#xe5; reflektere forskjeller gruppene (populasjonene) imellom. Dersom disse to variansestimatene ikke avviker s&#xe6;rlig mye fra hverandre, tas det til inntekt for &#xe5; hevde at alle gruppegjennomsnittene kommer fra samme fordeling, og at eventuelle forskjeller bare skyldes tilfeldig variasjon. I motsatt fall, dersom variansestimatene er betydelig forskjellige (alternativhypotesen <em>H</em><sub>1</sub>), vil man konkludere med at gruppegjennomsnittene kommer fra forskjellige fordelinger, og nullhypotesen, som sier at gjennomsnittene er like, vil bli forkastet.</p><p>Generelt vil variansanalyse kunne brukes til &#xe5; teste nullhypotesen:</p><p><em>H</em><sub>0</sub>: <em>&#xb5;</em><sub>1</sub> = <em>&#xb5;</em><sub>2</sub> = ....= <em>&#xb5;<sub>i</sub></em> (<em>i</em> = 1, 2, 3 ..., k)</p><p><em>H</em><sub>1</sub>: <em>&#xb5;</em><sub>1</sub> <em>&#x2260; &#xb5;</em><sub>2</sub> <em>&#x2260;</em> ....<em>&#x2260; &#xb5;<sub>i</sub></em> (<em>i</em> = 1, 2, 3 ..., k)</p><p>Her tester vi det ukjente gjennomsnittet i populasjon <em>i</em>. Populasjonene antas &#xe5; v&#xe6;re uavhengige, men &#xe5; ha samme varians.</p><div id="page-203" class="page-normal" epub:type="pagebreak" title="203"></div><table id="table_24"><tbody><tr><td rowspan="2" colspan="1"><strong>Respondent</strong></td><td colspan="5" rowspan="1"><strong>Stikkpr&#xf8;ve</strong></td></tr><tr><td rowspan="1" colspan="1"><strong>1</strong></td><td rowspan="1" colspan="1"><strong>2</strong></td><td rowspan="1" colspan="1"><strong>3</strong></td><td rowspan="1" colspan="1"><strong>i</strong></td><td rowspan="1" colspan="1"><strong>K</strong></td></tr><tr><td rowspan="1" colspan="1"><strong>1</strong></td><td rowspan="1" colspan="1">X<sub>11</sub></td><td rowspan="1" colspan="1">X<sub>21</sub></td><td rowspan="1" colspan="1">X<sub>31</sub></td><td rowspan="1" colspan="1">X<sub>i1</sub></td><td rowspan="1" colspan="1">X<sub>k1</sub></td></tr><tr><td rowspan="1" colspan="1"><strong>2</strong></td><td rowspan="1" colspan="1">X<sub>12</sub></td><td rowspan="1" colspan="1">X<sub>22</sub></td><td rowspan="1" colspan="1">X<sub>32</sub></td><td rowspan="1" colspan="1">X<sub>i2</sub></td><td rowspan="1" colspan="1">X<sub>k2</sub></td></tr><tr><td rowspan="1" colspan="1"><strong>3</strong></td><td rowspan="1" colspan="1"><sub>X13</sub></td><td rowspan="1" colspan="1">X<sub>23</sub></td><td rowspan="1" colspan="1">X<sub>33</sub></td><td rowspan="1" colspan="1">X<sub>i3</sub></td><td rowspan="1" colspan="1">X<sub>k3</sub></td></tr><tr><td rowspan="1" colspan="1"><strong>4</strong></td><td rowspan="1" colspan="1">X<sub>14</sub></td><td rowspan="1" colspan="1">X<sub>24</sub></td><td rowspan="1" colspan="1">X<sub>34</sub></td><td rowspan="1" colspan="1">X<sub>i4</sub></td><td rowspan="1" colspan="1">X<sub>k4</sub></td></tr><tr><td rowspan="1" colspan="1"><strong>J</strong></td><td rowspan="1" colspan="1">X<sub>1j</sub></td><td rowspan="1" colspan="1">X<sub>2j</sub></td><td rowspan="1" colspan="1">X<sub>3j</sub></td><td rowspan="1" colspan="1">X<sub>ij</sub></td><td rowspan="1" colspan="1">X<sub>kj</sub></td></tr><tr><td rowspan="1" colspan="1"><strong>N</strong></td><td rowspan="1" colspan="1">X<sub>1n1</sub></td><td rowspan="1" colspan="1">X<sub>2n2</sub></td><td rowspan="1" colspan="1">X<sub>3n3</sub></td><td rowspan="1" colspan="1">X<sub>iji</sub></td><td rowspan="1" colspan="1">X<sub>kjk</sub></td></tr></tbody></table><p>Tabell 9.5 Stikkpr&#xf8;ver fra utvalg.</p><p>For &#xe5; gjennomf&#xf8;re testen trekker vi uavhengige og tilfeldige utvalg (stikkpr&#xf8;ver) best&#xe5;ende av henholdsvis <em>n</em><sub>1</sub>, <em>n</em><sub>2</sub>, <em>n</em><sub>3</sub>, ..., <em>n<sub>k</sub></em> observasjoner fra hver populasjon. Tabell 9.5 viser hvordan vi kan tenke oss disse stikkpr&#xf8;vene organisert. <em>X<sub>ij</sub></em> betyr observasjon nr. <em>j</em> fra populasjon nr. <em>i</em>.</p><p>Som nevnt ovenfor er testen av nullhypotesen basert p&#xe5; sammenligningen av to typer m&#xe5;l for variasjon eller variabilitet: <em>variabilitet innenfor gruppen</em> og <em>variabilitet mellom gruppene</em>. Gruppen og gruppene er de <em>k-</em>stikkpr&#xf8;vene som er tilfeldig trukket ut fra sine respektive populasjoner.</p><p>For variansanalyse gjelder det at den totale variansen (<em>TSS</em>) best&#xe5;r av variansen innenfor gruppen (<em>SSIG</em>) pluss variansen mellom gruppene (<em>SSMG</em>). Dette kan vi illustrere gjennom f&#xf8;lgende:</p><p>total variabilitet = variabilitet innenfor gruppene + variabilitet mellom gruppene</p><p>TSS = SSIG + SSMG</p><p>Hvert av disse begrepene kan beregnes ved hjelp av formlene under.</p><section id="level4_68"><h3 id="h4_68">a) Variabilitet innenfor gruppene</h3><p><em>SSIG</em>: summen av variabilitet innenfor gruppene</p><p><span class="asciimath">`SSIG = sum_(i=1)^ksum_(j=1)^(n_i)(x_(ij)-barx)^2`</span></p><div id="page-204" class="page-normal" epub:type="pagebreak" title="204"></div><p><em>MSSIG:</em> summen av gjennomsnittet av variabiliteten innenfor gruppene</p><p><span class="asciimath">`MSSIG = (SSIG)/(n-k)`</span></p><p>Av formelen ser vi at gjennomsnittet av variabiliteten innenfor gruppene finner vi ved &#xe5; dele variansen innenfor gruppen <em>SSIG</em> p&#xe5; antall observasjoner <em>n</em> og antall grupper <em>k</em> (antall populasjoner). Derved vil <em>MSSIG</em> v&#xe6;re et forventningsrett estimat av populasjonens varians n&#xe5;r vi antar at <em>k-</em>populasjonene har samme varians.</p></section><section id="level4_69"><h3 id="h4_69">b) Variabiliteten mellom gruppene</h3><p><em>SSMG:</em> Variabiliteten mellom gruppene</p><p><span class="asciimath">`SSMG=sum_(i=1)^(k)n_i(barx_i - barX)^2`</span></p><p><span class="asciimath">`barX`</span>:Totalgjennomsnittet beregnes ved hjelp av formelen</p><p><span class="asciimath">`barX = 1/k (sum _(i=1)^(k)(1/n_isum_(j=1)^(n_i)X_(ij)))`</span></p><p><em>MSSMG:</em> Gjennomsnittet av variabiliteten mellom gruppene</p><p><span class="asciimath">`MSSMG = (SSMG)/(k - 1)`</span></p><p>For &#xe5; beregne variabiliteten mellom gruppene baserte vi oss p&#xe5; differansen mellom hvert enkelt gruppegjennomsnitt og totalgjennomsnittet. Gjennomsnittet av variabiliteten mellom gruppene finner vi ved &#xe5; ta variabiliteten mellom gruppene og dele p&#xe5; antall grupper k minus en. Dersom populasjonsgjennomsnittene er like, vil ogs&#xe5; <em>MSSMG</em> gitt ved formelen v&#xe6;re et forventningsrett estimat av den felles populasjonsvariansen.</p></section><section id="level4_70"><h3 id="h4_70">Testobservatoren F-fordelingen</h3><p>Dersom nullhypotesen er riktig, vil vi gjennom beregningene v&#xe6;re i besittelse av to forventningsrette estimater av samme st&#xf8;rrelse (populasjonsvariansen). Vi m&#xe5; kunne forvente at disse to estimatene ikke avviker betydelig fra hverandre. Dersom de skulle gj&#xf8;re det, kan vi mistenke <em>H<sub>0</sub></em> for &#xe5; v&#xe6;re usann. Testobservatoren <em>F</em> for nullhypotesen f&#xe5;r vi ved &#xe5; dividere de to estimatene med hverandre. Testobservatoren blir n&#xe5; beregnet ut fra denne formelen:</p><div id="page-205" class="page-normal" epub:type="pagebreak" title="205"></div><p><span class="asciimath">`F = (MSSMG)/(MSSIG)`</span></p><p>Dersom denne br&#xf8;ken er tiln&#xe6;rmet lik 1 (<em>F</em> = 1), vil de to variansestimatene v&#xe6;re tiln&#xe6;rmet like, og vi kan ikke forkaste <em>H</em><sub>0</sub>. Jo st&#xf8;rre br&#xf8;ken er, jo st&#xf8;rre vil mistanken om at <em>H</em><sub>0</sub> er usann, bli. N&#xe5;r vi jobber med F-fordelingen, tar vi ikke hensyn til ensidige eller tosidige tester. Dette ser man er logisk ut fra figuren under (se figur 9.8). F-fordelingen til variansanalysen kan illustreres p&#xe5; f&#xf8;lgende m&#xe5;te:</p><figure id="imggroup_97" class="image"><img id="img_97" src="images/image097.jpg" alt="image" /><figcaption id="caption_95">Figur 9.8 Grafisk framstilling av F-fordelingen for variansanalyse.</figcaption></figure><p>EKSEMPEL 9.3</p><p>Vi skal n&#xe5; g&#xe5; igjennom hvordan vi rent formelt utf&#xf8;rer en ANOVA-test i JMP. Vi bruker dataene vi har for l&#xf8;nnskostnader og ulike l&#xf8;nnskompensasjonssystemer. For &#xe5; kartlegge <em>hvilke</em> av disse tre gruppene med ulike l&#xf8;nnskompensasjoner som er statistisk signifikant forskjellig fra de andre gruppene, kj&#xf8;rer vi en ANOVA-test i JMP (se figur 9.9):</p><figure id="imggroup_98" class="image"><img id="img_98" src="images/image098.jpg" alt="image" /><figcaption id="caption_96">Figur 9.9 Dialogboks for ANOVA i JMP.</figcaption></figure><div id="page-206" class="page-normal" epub:type="pagebreak" title="206"></div><figure id="imggroup_99" class="image"><img id="img_99" src="images/image099.jpg" alt="image" /><figcaption id="caption_97">Tabell 9.6 Utskrift fra ANOVA i JMP.</figcaption></figure><p><em>Analyze &gt; Fit Y By X &gt; Y, Response &gt; X, Factor</em></p><p><em>R&#xf8;d trekant &gt; Means/Anova</em></p><p>I v&#xe5;rteksempel haddevitre kategorier innenforfastl&#xf8;nn, fastl&#xf8;nnogprovisjon, samt provisjon. Disse skal inn i X, Factor. Variabelen vi &#xf8;nsker &#xe5; teste i forhold til, skal inn for Y, Response. I v&#xe5;rt tilfelle er dette l&#xf8;nn for september 2010.</p><p>Det f&#xf8;rste vi legger merke til, er at <em>F</em>-verdien testen for &#xe5; teste variansen mellom gruppene i ANOVA er p&#xe5; 5,85 og at den er signifikant. Kritisk verdi finner vi i F-fordelingstabellen bak i boka (vedlegg 3C). Kritisk <span class="asciimath">`F_(k-1, n-k, alpha)`</span> finner vi ved at vi har <em>n</em> = 10 og <em>k</em> = 3. Frihetsgradstallet for antall grupper (<em>k</em>) er 2 ((<em>k</em>-1) = (3&#x2013;1) = 2), og frihetsgradstallet for antall observasjoner (<em>n</em>) er 7 ((<em>n - k) =</em> (10 -3) = 7). I tabellen finner vi at kritisk verdi for den tohalede <em>F</em>-verdien <span class="asciimath">`F_((k-1,n-k, alpha))`</span> er 4,74. F-tabellen leses ved at man leser av frihetsgradstallet for antall grupper langs den horisontale aksen (<em>k</em>-1) <em>v</em><sub>1</sub>og frihetsgradstallet for antall observasjoner <em>v</em><sub>2</sub> langs den vertikale aksen (<em>n</em>-<em>k</em>), gitt &#xf8;nsket signifikansniv&#xe5; <em>&#x3b1;</em> som er 0,05 for testen om minst en av gruppene er forskjellig fra de andre.</p><p>Ved &#xe5; sette testobservatoren opp mot kritisk verdi, finner vi at <em>F</em> 5.85 &gt; <span class="asciimath">`F_((k-1,n-k, alpha))`</span> 4,74. <em>Vi kan derved med 95 % sikkerhet anta at minst en av gruppene er forskjellig fra de andre gruppene.</em> Dette leser vi for &#xf8;vrig ogs&#xe5; rett ut fra ANOVA-utskriften i JMP, hvor P-verdien er 0,03, noe som tilsvarer 97 % sikkerhet, alts&#xe5; h&#xf8;yere enn v&#xe5;rt krav p&#xe5; 95 %, og det er bra.</p><div id="page-207" class="page-normal" epub:type="pagebreak" title="207"></div><figure id="imggroup_100" class="image"><img id="img_100" src="images/image100.jpg" alt="image" /><figcaption id="caption_98">Tabell 9.7 Utskrift fra ANOVA for test av parvise kategorier.</figcaption></figure><p>For &#xe5; finne hvilke av gruppene som individuelt er forskjellige fra hverandre, tester vi hvert par av kategorier mot hverandre. Dette gj&#xf8;r vived &#xe5; velge f&#xf8;lgende:</p><p><em>R&#xf8;d trekant &gt; Compare Means &gt; Each Pair, Students t</em></p><p>Resultatet fra denne testen er gjengitt i tabell 9.7.</p><p>Vi ser at fastl&#xf8;nn har 8 970 kroner <em>lavere</em> l&#xf8;nn enn en kombinert l&#xf8;nn best&#xe5;ende av fastl&#xf8;nn og provisjon. Denne forskjellen er <em>ikke</em> stor nok til at den er statistisk signifikant (sig. 0,25). Videre ser vi at de med fastl&#xf8;nn har 22 608 kroner lavere l&#xf8;nn enn de med provisjonsl&#xf8;nn. Denne forskjellen er stor nok til &#xe5; v&#xe6;re statistisk signifikant (sig. 0,012). For den siste gruppen ser vi at kombinasjonsl&#xf8;nnen er 13 638 kroner lavere enn provisjonsl&#xf8;nnen. Denne forskjellen er heller ikke stor nok til &#xe5; v&#xe6;re statistisk signifikant p&#xe5; 5 %-niv&#xe5;et (sig. 0,08). Sirklene i grafen i JMP illustrerer disse sammenhengene. Vi har markert provisjonsl&#xf8;nn, og ser at den kun er statistisk signifikant forskjellig fra fastl&#xf8;nn.</p><p><em>Konklusjonen</em> av testen er med andre ord at vi finner den st&#xf8;rste forskjellen mellom fastl&#xf8;nn og provisjonsl&#xf8;nn. Denne trenden ser vi ogs&#xe5; i den grafiske <span id="page-208" class="page-normal" epub:type="pagebreak" title="208"></span>framstillingen av ANOVA-en, hvor den st&#xf8;rste forskjellen nettopp er mellom fastl&#xf8;nn og provisjonsl&#xf8;nn, med kombinasjonsl&#xf8;nnen i midten.</p></section></section><section id="level3_56"><h2 id="h3_56">9.5 Kji-kvadrattesten (Kji<sup>2</sup>)</h2><p>Nye symboler i avsnittet for Kji-kvadrattesten:</p><table id="table_25"><tbody><tr><td rowspan="1" colspan="1"><em>Kji</em><sup>2</sup></td><td rowspan="1" colspan="1">Kji-kvadratet</td></tr><tr><td rowspan="1" colspan="1">Corr</td><td rowspan="1" colspan="1">Persons korrelasjonskoeffisient</td></tr><tr><td rowspan="1" colspan="1"><em>SR</em></td><td rowspan="1" colspan="1">Spearmans korrelasjonskoeffisient</td></tr><tr><td rowspan="1" colspan="1"><em>O<sub>i</sub></em></td><td rowspan="1" colspan="1">Observert ruteverdi</td></tr><tr><td rowspan="1" colspan="1"><em>E<sub>i</sub></em></td><td rowspan="1" colspan="1">Estimert ruteverdi</td></tr><tr><td rowspan="1" colspan="1"><em>v</em></td><td rowspan="1" colspan="1">antall frihetsgrader</td></tr><tr><td rowspan="1" colspan="1"><em>X</em><sup>2</sup></td><td rowspan="1" colspan="1">testobservatoren til Kji-kvadratfordelingen</td></tr><tr><td rowspan="1" colspan="1"><em>X</em><sub>&#x3b1;</sub><sup>2</sup></td><td rowspan="1" colspan="1">kritisk verdi for Kji-kvadratfordelingen</td></tr></tbody></table><p>Avhengighet og sammenheng mellom variabler er et tema som st&#xe5;r sentralt innenfor mange fagomr&#xe5;der, alt fra logistikk, finans, organisasjon og ledelse, markedsf&#xf8;ring, strategi, kommunikasjon, styringsformer, samfunns&#xf8;konomi, innovasjon og &#xf8;konomistyring. Det er utviklet mange statistiske metoder for &#xe5; kunne studere og teste sammenhenger mellom variabler. En av de mest brukte metodene er regresjonsanalyse. Denne metoden vil bli behandlet i et eget kapittel. Det som imidlertid er en forutsetning for at regresjonsanalysen skal fungere optimalt, er at dataene er kontinuerlige, det vil si at de minst m&#xe5; v&#xe6;re p&#xe5; intervallniv&#xe5;. Dersom vi har data p&#xe5; &#xab;lavere&#xbb; m&#xe5;leniv&#xe5; (jf. tabell 8.1), m&#xe5; vi bruke andre former for tester. <em>Kji-kvadrattesten kan brukes til &#xe5; teste eventuelle sammenhenger mellom variabler som er p&#xe5; nominalniv&#xe5;</em>. Testen er imidlertid ikke helt valid dersom antall observasjoner per rute blir for lite. Dette kommer av at testen bygger p&#xe5; at normaltiln&#xe6;rmingen kan benyttes (se Wenst&#xf8;p, 2006). Det anbefales derfor at antall observasjoner per rute ikke er under 5.</p><section id="level4_71"><h3 id="h4_71">Frekvensvise forskjeller</h3><p>La oss starte med et enkelt (tenkt) eksempel: Vi vil unders&#xf8;ke om det er noen sammenheng mellom variablene <em>holdning til fremtiden</em> og <em>fagretning</em>. Er det slik at fremtidsutsiktene avhenger av hva slags fagretning man har? Ser for eksempel folk innen samfunns&#xf8;konomi lysere p&#xe5; fremtiden enn finans- og markedsf&#xf8;rere? Vi har sammenlignet de tre fagomr&#xe5;dene, og alle blir s&#xe5; bedt om &#xe5; velge ett av disse tre alternativene:</p><div id="page-209" class="page-normal" epub:type="pagebreak" title="209"></div><ul id="list_93"><li id="li_384">Jeg tror p&#xe5; minsket aktivitet og nedgangstider (nedgang).</li><li id="li_385">Jeg tror ikke p&#xe5; noen endring, det vil stort sett v&#xe6;re som i dag (ingen endring).</li><li id="li_386">Jeg tror p&#xe5; &#xf8;kt aktivitet og oppgangstider (&#xf8;kning).</li></ul><p>Gitt at 140 personer innenfor disse tre fagomr&#xe5;dene ble tilfeldig plukket ut og stilt disse tre sp&#xf8;rsm&#xe5;lene. Vi kan tenke oss at svarene fordelte seg som tabellen under (tabell 9.8):</p><table id="table_26"><tbody><tr><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><strong>nedgang</strong></td><td rowspan="1" colspan="1"><strong>uendret</strong></td><td rowspan="1" colspan="1"><strong>oppgang</strong></td><td rowspan="1" colspan="1"><strong>REKKESUM</strong></td></tr><tr><td rowspan="1" colspan="1"><strong>Finans</strong></td><td rowspan="1" colspan="1">19</td><td rowspan="1" colspan="1">12</td><td rowspan="1" colspan="1">15</td><td rowspan="1" colspan="1">46</td></tr><tr><td rowspan="1" colspan="1"><strong>Samfunns&#xf8;konomi</strong></td><td rowspan="1" colspan="1">8</td><td rowspan="1" colspan="1">20</td><td rowspan="1" colspan="1">38</td><td rowspan="1" colspan="1">66</td></tr><tr><td rowspan="1" colspan="1"><strong>Markedsf&#xf8;ring</strong></td><td rowspan="1" colspan="1">8</td><td rowspan="1" colspan="1">10</td><td rowspan="1" colspan="1">10</td><td rowspan="1" colspan="1">28</td></tr><tr><td rowspan="1" colspan="1"><strong>KOLONNESUM</strong></td><td rowspan="1" colspan="1">35</td><td rowspan="1" colspan="1">42</td><td rowspan="1" colspan="1">63</td><td rowspan="1" colspan="1">140 (Totalsum)</td></tr></tbody></table><p>Tabell 9.8 Krysstabell.</p><p>Ut fra tabellen ser vi p&#xe5; frekvensen at 15 av 46 finansfolk tror p&#xe5; oppgangstider, mens det tilsvarende tallet er 38 av 66 samfunns&#xf8;konomer. Av markedsf&#xf8;rerne er det i underkant av 10 av 28 som er optimistiske. Vi observerer alts&#xe5; forskjeller mellom faggruppene, men som vi ser, er det vanskelig &#xe5; sammenligne frekvenser. Det kan derfor v&#xe6;re hensiktsmessig &#xe5; sammenligne prosentvise forskjeller mellom rutene.</p><section id="level5_26"><h4 id="h5_26">Prosentvise forskjeller</h4><p>Prosentvise forskjeller mellom rutene beregnes p&#xe5; f&#xf8;lgende m&#xe5;te:</p><ul id="list_94"><li id="li_387">prosentuering basert p&#xe5; kolonnesum</li><li id="li_388">prosentuering basert p&#xe5; rekkesum</li><li id="li_389">prosentuering basert p&#xe5; totalsum</li></ul><p>Prosentuering beregnes p&#xe5; basis av de uavhengige variablene. La oss ta de innen finans som eksempel. Vi har summert alle prosentueringene fra eksemplet i tabell 9.9.</p><p>Prosentuering basert p&#xe5; <em>kolonnesum</em> forteller oss at <span class="asciimath">`54,29 % (19 ** 100// 35 = 54,29)`</span> av dem som tror p&#xe5; en nedgangstid, er finansfolk. Prosentuering basert p&#xe5; <em>rekkesum</em> viser at <span class="asciimath">`41,30 % (19 * 100// 46 = 41,30)`</span> av finansfolkene tror p&#xe5; nedgangstider. Legg merke til forskjellen mellom &#xab;er finans&#xbb; (kolonnesum) og &#xab;av finans&#xbb; (rekkesum). Til slutt kan vi beregne at prosentuering basert p&#xe5; <em>totalsum</em> forteller oss at <span class="asciimath">`25 % (35 * 100//140 = 25)`</span> av totalen tror p&#xe5; nedgangstider.</p></section><section id="level5_27"><div id="page-210" class="page-normal" epub:type="pagebreak" title="210"></div><h4 id="h5_27">Signifikante forskjeller</h4><figure id="imggroup_101" class="image"><img id="img_101" src="images/image101.jpg" alt="image" /><figcaption id="caption_99">Tabell 9.9 Prosentvise forskjeller i krysstabell.</figcaption></figure><p>Vi observerer alts&#xe5; forskjeller mellom faggruppene, men kan vi anta at det er et <em>statistisk signifikant</em> m&#xf8;nster? I s&#xe5; fall vil vi kunne si at det er en statistisk signifikant <em>sammenheng</em> i m&#xf8;nsteret mellom fagomr&#xe5;de og holdning til fremtiden. I krysstabeller bruker vi <em>Kji</em>-kvadrattesten for &#xe5; teste om det er statistisk signifikant m&#xf8;nster mellom variablene. <em>Kji</em>-kvadrattesten gjennomf&#xf8;res etter f&#xf8;lgende oppsett:</p></section><section id="level5_28"><h4 id="h5_28">1 Hypoteseformulering</h4><p>Nullhypotese og alternativ hypotese formuleres, og signifikansniv&#xe5; bestemmes:</p><ol id="list_95" class="list-style-type-none"><li id="li_390"><em>H</em><sub>0</sub>: Det er ingen sammenheng mellom variablene</li><li id="li_391"><em>H</em><sub>1</sub>: Det er en sammenheng mellom variablene</li></ol><p>Vanligvis benytter en 5 % signifikansniv&#xe5; p&#xe5; Kji-kvadrattesten.</p></section><section id="level5_29"><div id="page-211" class="page-normal" epub:type="pagebreak" title="211"></div><h4 id="h5_29">2 Beregne forventningsverdi</h4><p>Man beregner de forventede verdiene <em>E<sub>i</sub></em> for hver av rutene i krysstabellen, gitt at det ikke er noen sammenheng mellom variablene. For rute nummer &#xe9;n i krysstabellen (samfunns&#xf8;konomi og nedgang) blir dette:</p><p><span class="asciimath">`E_i= (" rekkesum " * " kolonnesum ")/(" totalsum ") = (35*46)/(140) = 11,5`</span></p><p>Forventningsverdien <em>E<sub>i</sub></em> til rute &#xe9;n er med andre ord 11,5, mens den observerte verdien <em>O<sub>i</sub></em> er 19 (verdien i ruten).</p></section><section id="level5_30"><h4 id="h5_30">3 Beregne relativ kvadrert differanse</h4><p>Deretter beregnes den &#xab;relative kvadrerte differansen&#xbb; mellom den observerte verdien <em>O<sub>i</sub></em> og den forventede verdien <em>E<sub>i</sub></em> for hver rute. For rute &#xe9;n blir dette:</p><p><span class="asciimath">`Rute &#xe9;n = ((O_i - E_i)^2)/(E_i) = ((19 - 11,5)^2)/(11,5) = 4,89`</span></p><p>Den relative kvadrerte differansen mellom observert verdi <em>O<sub>i</sub></em> og den forventede verdien <em>E<sub>i</sub></em> for rute &#xe9;n er 4,89.</p></section><section id="level5_31"><h4 id="h5_31">4 Beregne Kji-kvadratet</h4><p>Summen av de <em>relative kvadrerte differansene</em> er <em>Kji<sup>2</sup></em>-verdien. Den beregnes etter f&#xf8;lgende formel:</p><p><span class="asciimath">`KJI = ((O_i-E_i))/(E_i)=((19-11,5)^2)/(11,5)+((8-16,5)^2)/(16,5)+...+((10-12,6)^2)/(12,6)=14,308`</span></p><p>Kji-kvadratet er 14,308. Vi ser at jo st&#xf8;rre avvik det er mellom observert verdi <em>O<sub>i</sub></em> og forventningsverdi <em>E<sub>i</sub></em> estimert verdi, jo st&#xf8;rre vil <em>Kji<sup>2</sup>-verdien</em> bli.</p><p>Verdien p&#xe5; <em>Kji</em>-kvadratet kan vi sjekke i tabellen for <em>Kji</em>-kvadratfordelingen. Da trenger vi imidlertid &#xe5; kjenne antall frihetsgrader. Frihetsgradene finner vi enkelt etter f&#xf8;lgende formel:</p><p><span class="asciimath">`v = ("antall rader -1")*("antall kolonner -1") = (3 -1)*(3 - 1) = 4`</span></p><p>Antall frihetsgrader, <em>v</em>, er i v&#xe5;rt eksempel 4. For &#xe5; vite om <em>Kji-kvadratet</em> p&#xe5; 14.38 er tilstrekkelig for at sammenhengen mellom variablene ikke kun skyldes tilfeldigheter (at det er statistisk signifikant sammenheng), m&#xe5; vi vurdere Kji-kvadratet opp mot kritisk verdi i <em>Kji</em>-kvadratfordelingen. Denne kritiske verdi har symbolet <span class="asciimath">`X_alpha`</span> i tabell 3A bak i boka. Fra tabellen finner vi at kritisk verdi til <em>Kji</em>-kvadratfordelingen ved 4 frihetsgrader og 5 % signifikansniv&#xe5; er 9,49.</p><div id="page-212" class="page-normal" epub:type="pagebreak" title="212"></div><p>Som vi ser er testobservatoren p&#xe5; 14,308 st&#xf8;rre enn 9,49, og vi p&#xe5;st&#xe5;r at alternativet er riktig. Dette betyr at vi forkaster nullhypotesen at det ikke er noen sammenheng mellom variablene. Vi ser derved at det er et statistisk signifikant m&#xf8;nster mellom fagomr&#xe5;de og holdning til fremtiden. Vi kan med andre ord v&#xe6;re 95 % sikker p&#xe5; at m&#xf8;nsteret i sammenhengen mellom fagomr&#xe5;de og holdning til fremtiden ikke kun skyldes tilfeldigheter.</p><p>Vi fikk resultatet fra <em>Kji</em>-kvadrattesten n&#xe5;r vi kj&#xf8;rte krysstabellen i tabell 9.9. Dersom vi &#xf8;nsker &#xe5; f&#xe5; vite hva forventningsverdiene til hver av cellene er, velger man</p><p><em>R&#xf8;d trekant &gt; Expected</em></p><p>I utskriften fra <em>Kji</em>-kvadratet f&#xe5;r vi direkte opp signifikansniv&#xe5;et i utskriften, slik at vi slipper &#xe5; sl&#xe5; opp i tabellen. Vi ser at vi har et signifikansniv&#xe5; p&#xe5; 0,006, noe som er sv&#xe6;rt bra (det m&#xe5; v&#xe6;re lavere enn 0,05, som er kravet vi stiller). Vi er derfor minst 99 % sikre p&#xe5; at m&#xf8;nsteret i sammenhengen mellom holdning til fremtiden og fagomr&#xe5;de ikke kun skyldes tilfeldigheter.</p><p><em>Konklusjonen</em> er at det er et signifikant m&#xf8;nster i forholdet mellom holdning til fremtiden og fagomr&#xe5;de. Fra krysstabellen ser vi at samfunns&#xf8;konomer ser ut til &#xe5; ha mest positivt syn, mens folk innenfor finans ser ut til &#xe5; ha mest negativt syn p&#xe5; fremtiden. Markedsf&#xf8;rere ser ut til &#xe5; havne ganske jevnt mellom kategoriene. En krysstabell med prosentfordeling forteller oss kun prosentandelen av hvor mange som mener hva innenfor hver rute, mens en krysstabell med frekvensfordeling kun forteller oss hvor mange som mener noe innenfor hver av kategoriene. For &#xe5; kunne si noe om hvordan st&#xf8;rrelsene i rutene forholder seg til hverandre, trenger vi andre analyser, noe vi skal se p&#xe5; under korrelasjonsko-effisient i neste avsnitt.</p></section></section></section><section id="level3_57"><h2 id="h3_57">9.6 Testing av korrelasjonskoeffisienten</h2><p>Tidligere definerte vi to korrelasjonskoeffisienter: Pearson-korrelasjonen (<em>Corr</em>) og Spearmans rangkorrelasjon (<em>SR</em>). Vi skal n&#xe5; se hvordan vi kan teste om en korrelasjonskoeffisient mellom to variabler <em>X</em> og <em>Y</em> er <em>statistisk signifikant</em> forskjellig fra null.</p><p>I dette avsnittet skal vi bruke f&#xf8;lgende symboler og begreper:</p><table id="table_27"><tbody><tr><td rowspan="1" colspan="1"><em>&#x3c1;</em></td><td rowspan="1" colspan="1">populasjonsverdien</td></tr><tr><td rowspan="1" colspan="1"><em>X</em></td><td rowspan="1" colspan="1">variabel <em>X</em></td></tr><tr><td rowspan="1" colspan="1"><em>Y</em></td><td rowspan="1" colspan="1">variabel <em>Y</em></td></tr><tr><td rowspan="1" colspan="1"><em>Corr</em></td><td rowspan="1" colspan="1">Persons korrelasjonskoeffisient</td></tr><tr><td rowspan="1" colspan="1"><em>SR</em></td><td rowspan="1" colspan="1">Spearmans korrelasjonskoeffisient</td></tr></tbody></table><section id="level4_72"><div id="page-213" class="page-normal" epub:type="pagebreak" title="213"></div><h3 id="h4_72">Pearson-korrelasjonen</h3><p>F&#xf8;rst skal vi l&#xe6;re om <em>Pearson-korrelasjonen</em> (den mest vanlige). Vi tester nullhypotesen om at det ikke er noen korrelasjon (<em>Corr</em>) mellom variabel <em>X</em> og variabel <em>Y</em>, og alternativhypotesen <em>H</em><sub>1</sub> at det er en korrelasjon mellom <em>X</em> og <em>Y</em>. Dette skriver vi opp som hypotese:</p><p><em>H<sub>0</sub></em> : <em>&#x3c1;</em> = 0</p><p><em>H</em><sub>1</sub> : <em>&#x3c1; &#x2260;</em> 0</p><p>Testobservatoren, som er t-fordelt, kan beregnes etter formelen: Testobservatoren</p><p><span class="asciimath">`t = ("Corr"(X, Y))/(sqrt((1-"Corr"(X,Y)^2)/(n - 2)))`</span></p><p>Frihetsgradene <em>v</em> er antall observasjoner minus 2 (<em>n</em> &#x2013; 2). Nullhypotesen forkastes dersom |<em>t</em>| er st&#xf8;rre enn den kritiske verdi <em>t<sub>a</sub></em>, som vi finner i t-fordelingstabellen 3B i vedlegg 3.</p><p>Vi beregnet tidligere (en tenkt) korrelasjon for salgsvekst og l&#xf8;nnsvekst i hotelln&#xe6;ringen. Vi fant at korrelasjonen mellom salgsvekst og l&#xf8;nnsvekst var p&#xe5; 0,498. Vi skal n&#xe5; vise hvordan denne korrelasjonen er testet ved hjelp av JMP:</p><blockquote id="quote_2"><p><em>Analyze &gt; Multivariate Modeling &gt; Multivariate &gt; Y, Columns</em></p><p><em>R&#xf8;d trekant &gt; Pairwise Correlations</em></p></blockquote><p>Utskrift fra korrelasjonsanalysen finner du i tabell 9.10.</p><p>Legg merke til at JMP i default (automatisk) kj&#xf8;rer tosidig test p&#xe5; signifikans-niv&#xe5;et. Dette betyr at vi tester om det er en sammenheng, uten &#xe5; spesifisere retningen (vi tar ikke hensyn til om det er en positiv eller negativ sammenheng). Fordi vi i v&#xe5;r hypotese p&#xe5;sto en <em>forskjell</em> i sammenheng mellom salgsvekst og l&#xf8;nnsvekst, lar vi tosidig test best&#xe5;. P&#xe5; linjen med Signif Prob kan vi lese ut signifikansniv&#xe5;et direkte. I eksemplet er signifikansniv&#xe5;et p&#xe5; p  &lt;  0,001. Dette betyr at vi har f&#xe5;tt en statistisk signifikant korrelasjon mellom l&#xf8;nnskostnader og produksjonskostnader ved hotellet.</p><p>Vi kan ogs&#xe5; beregne disse verdiene ved hjelp av statistiske formler. Antall observasjoner er 140, og antall frihetsgrader <em>v</em> er da p&#xe5; (140 - 2 = 138).</p><figure id="imggroup_102" class="image"><img id="img_102" src="images/image102.jpg" alt="image" /><figcaption id="caption_100">Tabell 9.10 Utskriften fra korrelasjonsanalysen i JMP.</figcaption></figure><div id="page-214" class="page-normal" epub:type="pagebreak" title="214"></div><p>Vi setter disse verdiene inn i formelen for &#xe5; finne testobservatoren t. Testobservator</p><p><span class="asciimath">`t = (" Corr" (X,Y))/sqrt((1 - " Corr " (X,Y)^2)/(n - 2))=(0,498)/sqrt((1-0,498^2)/(140-2)) = 6,747`</span></p><p>Testobservatoren er med andre ord 6,747. If&#xf8;lge tabellen for t-fordelingen i vedlegg 3B bak i boka er kritisk verdi p&#xe5; 1,960 ved <em>a</em> p&#xe5; 0,025, det vil si 5 % signifikansniv&#xe5; (tosidig test) og 120 frihetsgrader. Ettersom |t| &gt; <span class="asciimath">`t_(alpha//2)`</span> (6,747 &gt; 1,960), forkaster vi nullhypotesen.</p><p><em>Konklusjonen</em> eratkorrelasjonen mellom salgsvekstogl&#xf8;nnsvekster p&#xe5;0,498, og denne korrelasjonen er signifikant forskjellig fra null p&#xe5; 5 %-niv&#xe5;et. Vi kan derfor anta at det er samvariasjon mellom salgsvekst og l&#xf8;nnsvekst.</p></section><section id="level4_73"><h3 id="h4_73">Spearmans rangkorrelasjon</h3><p>Signifikanstesten av Spearmans rangkorrelasjon er identisk med Pearsons korrelasjon, bortsett fra n&#xe5;r antall observasjoner er under 10. I slike tilfeller bruker vi Spearman-koeffisienten. N&#xe5;r vi har 10 eller flere observasjoner, bruker vi t-forde-lingen som ved Pearsons korrelasjon. Utregningen av testobservatoren er identisk for Spearmans rangkorrelasjon og for Pearsons korrelasjon, bortsett fra at vi n&#xe5; bruker Spearmans rangkorrelasjon <em>SR</em> i ligningen. Dette gir f&#xf8;lgende ligning: Testobservatoren</p><p><span class="asciimath">`t = (SR)/sqrt((1-SR^2)/(n - 2))`</span></p><p>I eksemplet i kapittel 8 fant vi at <em>SR</em>-korrelasjonen mellom l&#xf8;nnsvekst og salgs-vekst var p&#xe5; 0,492. Vi setter dette inn i formelen for &#xe5; finne verdien p&#xe5; test-observatoren.</p><p>Testobservatoren</p><p><span class="asciimath">`t = (SR)/sqrt ((1 - SR^2)/(n - 2)) = (0,501)/sqrt ((1 - 0,501^2)/(140-2)) = 6,807`</span></p><p>Testobservatoren |<em>t</em>| i eksemplet v&#xe5;rt er p&#xe5; 6,807. Vi m&#xe5; sjekke denne verdien i forhold til kritisk verdi (<em>t</em><sub>&#x3b1;/2</sub>), og for 140 frihetsgrader ((<em>n -</em> 2) = (140 - 2) = 138) finner vi i tabellen for t-fordelingen at kritisk verdi er 1,960. Fordi testobserva-toren er st&#xf8;rre enn kritisk verdi (6,807 &gt; 1,960), er <em>SR</em>- korrelasjonen statistisk signifikant. Signifikansniv&#xe5;et for Spearmans rangkorrelasjon kommer automatisk opp n&#xe5;r man velger den analysen:</p><p><em>Analyze</em> &gt; <em>Multivariate Modeling</em> &gt; <em>Multivariate</em> &gt; <em>Y, Columns R&#xf8;d trekant</em> &gt; <em>Nonparametric Correlations</em> &gt; <em>Spearman's p</em></p><div id="page-215" class="page-normal" epub:type="pagebreak" title="215"></div><figure id="imggroup_103" class="image"><img id="img_103" src="images/image103.jpg" alt="image" /><figcaption id="caption_101">Tabell 9.11 Spearmans rangkorrelasjon i JMP.</figcaption></figure><p>Testen forteller oss at korrelasjonen mellom l&#xf8;nnskostnader og tilfredshet er p&#xe5; p  &lt;  0,001-niv&#xe5; (legg merke til at vi i metode og dataanalyse <em>aldri</em> bruker benevnelsen p = 0,000-niv&#xe5;, men p  &lt;  0,001).</p><aside id="sidebar_30" class="sidebar" epub:type="sidebar">
<p><strong>9.7 Oppsummering</strong></p>
<p>Hypotesetesting dreier seg om aksept eller forkastelse av en nullhypotese. Om nullhypotesen skal gis st&#xf8;tte for eller forkastes, avgj&#xf8;res av det valgte signifikansniv&#xe5;et og den aktuelle testobservator. Testobservatoren beregnes forskjellig alt etter hvilken sannsynlighetsfordeling som ligger til grunn for testen. Det som er det avgj&#xf8;rende i enhver test, er om den aktuelle testobservator avviker mer fra null enn det vi skulle forvente <em>dersom nullhypotesen var riktig</em>. Vanligvis avgj&#xf8;res dette ved &#xe5; sammenligne testobservatoren med <em>kritiske verdier</em> for den aktuelle sannsynlighetsfordelingen. Kritiske verdier er angitt i tabeller i de fleste innf&#xf8;ringsb&#xf8;ker i statistikk.</p>
<p>Vi har sett p&#xe5; <em>Student t-test</em> for &#xe5; teste om korrelasjonskoeffisienten mellom to variabler er signifikant forskjellig fra null. Vi har ogs&#xe5; sett hvordan vi kan bruke Student t-test til &#xe5; teste hypoteser vedr&#xf8;rende populasjons-gjennomsnittet for en og to stikkpr&#xf8;ver.</p>
<p>Videre har vi presentert <em>Kji-kvadrat</em>-testen for &#xe5; teste sammenhenger mellom variabler p&#xe5; nominalniv&#xe5;.</p>
<p>I <em>variansanalysen</em> utvidet vi dette til flere enn to stikkpr&#xf8;ver (populasjoner). Variansanalysen kan dermed sees p&#xe5; som en generalisering av t-testen for to gjennomsnitt. Testobservatoren er imidlertid ikke t-for-delt lenger. Siden testobservatoren n&#xe5; beregnes som forholdet mellom to variansestimater, kan det vises at den rette sannsynlighetsfordelingen er <em>F</em>-<em>fordelingen</em>.</p>
</aside></section></section>
</body>
</html>